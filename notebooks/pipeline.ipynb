{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9k58g3lYmjXS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Speech emotion recognition\n",
    "\n",
    "\n",
    "#### First, lets define SER i.e. Speech Emotion Recognition.\n",
    "\n",
    "*Speech Emotion Recognition*, abbreviated as *SER*, is the act of attempting to recognize human emotion and affective states from speech.\n",
    "This is capitalizing on the fact that voice often reflects underlying emotion through tone and pitch. This is also the phenomenon\n",
    "that animals like dogs and horses employ to be able to understand human emotion\n",
    "\n",
    "**Datasets used in this project** contains ~7 types of main emotions: *Happy, Fear, Angry, Disgust, Surprised, Sad or Neutral.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XexRcswdmjXa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:04:47.035691Z",
     "iopub.status.busy": "2023-01-30T21:04:47.035437Z",
     "iopub.status.idle": "2023-01-30T21:04:53.741705Z",
     "shell.execute_reply": "2023-01-30T21:04:53.740797Z",
     "shell.execute_reply.started": "2023-01-30T21:04:47.035665Z"
    },
    "id": "Mk52MU2GGaf5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "# from entropy import spectral_entropy\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:04:57.071299Z",
     "iopub.status.busy": "2023-01-30T21:04:57.070925Z",
     "iopub.status.idle": "2023-01-30T21:04:57.075699Z",
     "shell.execute_reply": "2023-01-30T21:04:57.074774Z",
     "shell.execute_reply.started": "2023-01-30T21:04:57.071260Z"
    },
    "id": "q7WxRfETGagD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Paths to\n",
    "Ravdess = \"../input/speech-emotion-recognition-en/Ravdess/audio_speech_actors_01-24\"\n",
    "Crema = \"../input/speech-emotion-recognition-en/Crema\"\n",
    "Savee = \"../input/speech-emotion-recognition-en/Savee\"\n",
    "Tess = \"../input/speech-emotion-recognition-en/Tess\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orXXFgDMGagF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igpdLfEknMks"
   },
   "source": [
    "### Ravdess dataset\n",
    "\n",
    "Here is the filename identifiers as per the official RAVDESS website:\n",
    "\n",
    "* Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "* Vocal channel (01 = speech, 02 = song).\n",
    "* Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "* Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "* Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "* Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "* Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
    "\n",
    "So, here's an example of an audio filename. 02-01-06-01-02-01-12.mp4 This means the meta data for the audio file is:\n",
    "\n",
    "* Video-only (02)\n",
    "* Speech (01)\n",
    "* Fearful (06)\n",
    "* Normal intensity (01)\n",
    "* Statement \"dogs\" (02)\n",
    "* 1st Repetition (01)\n",
    "* 12th Actor (12) - Female (as the actor ID number is even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:04:59.438259Z",
     "iopub.status.busy": "2023-01-30T21:04:59.437927Z",
     "iopub.status.idle": "2023-01-30T21:05:00.379481Z",
     "shell.execute_reply": "2023-01-30T21:05:00.378611Z",
     "shell.execute_reply.started": "2023-01-30T21:04:59.438226Z"
    },
    "id": "IHxQ_uFbGagG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ravdess_directory_list = os.listdir(Ravdess)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for dir in ravdess_directory_list:\n",
    "    actor = os.listdir(os.path.join(Ravdess, dir))\n",
    "    for wav in actor:\n",
    "        info = wav.partition(\".wav\")[0].split(\"-\")\n",
    "        emotion = int(info[2])\n",
    "        emotion_df.append((emotion, os.path.join(Ravdess, dir, wav)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:01.637738Z",
     "iopub.status.busy": "2023-01-30T21:05:01.637425Z",
     "iopub.status.idle": "2023-01-30T21:05:01.650966Z",
     "shell.execute_reply": "2023-01-30T21:05:01.650181Z",
     "shell.execute_reply.started": "2023-01-30T21:05:01.637709Z"
    },
    "id": "JP7zOhLrGagG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Ravdess_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Ravdess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:03.062330Z",
     "iopub.status.busy": "2023-01-30T21:05:03.061989Z",
     "iopub.status.idle": "2023-01-30T21:05:03.082585Z",
     "shell.execute_reply": "2023-01-30T21:05:03.081620Z",
     "shell.execute_reply.started": "2023-01-30T21:05:03.062298Z"
    },
    "id": "AFPKUvxJGagH",
    "outputId": "4de2e2fd-2886-461a-9298-f38a9135a611",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Ravdess_df.Emotion.replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "Ravdess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwrVbdYMGagK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Crema dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:05.704452Z",
     "iopub.status.busy": "2023-01-30T21:05:05.704104Z",
     "iopub.status.idle": "2023-01-30T21:05:06.383992Z",
     "shell.execute_reply": "2023-01-30T21:05:06.383208Z",
     "shell.execute_reply.started": "2023-01-30T21:05:05.704420Z"
    },
    "id": "s68VyjNdGagK",
    "outputId": "2b91980e-0977-47f1-a99b-50b45fd8aa42",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotion_df = []\n",
    "\n",
    "for wav in os.listdir(Crema):\n",
    "    info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "    if info[2] == 'SAD':\n",
    "        emotion_df.append((\"sad\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'ANG':\n",
    "        emotion_df.append((\"angry\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'DIS':\n",
    "        emotion_df.append((\"disgust\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'FEA':\n",
    "        emotion_df.append((\"fear\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'HAP':\n",
    "        emotion_df.append((\"happy\", Crema + \"/\" + wav))\n",
    "    elif info[2] == 'NEU':\n",
    "        emotion_df.append((\"neutral\", Crema + \"/\" + wav))\n",
    "    else:\n",
    "        emotion_df.append((\"unknown\", Crema + \"/\" + wav))\n",
    "\n",
    "\n",
    "Crema_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Crema_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Crema_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24EeU87cGagL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TESS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:08.418445Z",
     "iopub.status.busy": "2023-01-30T21:05:08.418079Z",
     "iopub.status.idle": "2023-01-30T21:05:10.050735Z",
     "shell.execute_reply": "2023-01-30T21:05:10.049632Z",
     "shell.execute_reply.started": "2023-01-30T21:05:08.418413Z"
    },
    "id": "R5yWxQLYGagM",
    "outputId": "8ef3022c-d2ec-4789-88dd-8b06adee745b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tess_directory_list = os.listdir(Tess)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for dir in tess_directory_list:\n",
    "    for wav in os.listdir(os.path.join(Tess, dir)):\n",
    "        info = wav.partition(\".wav\")[0].split(\"_\")\n",
    "        emo = info[2]\n",
    "        if emo == \"ps\":\n",
    "            emotion_df.append((\"surprise\", os.path.join(Tess, dir, wav)))\n",
    "        else:\n",
    "            emotion_df.append((emo, os.path.join(Tess, dir, wav)))\n",
    "\n",
    "\n",
    "Tess_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Tess_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Tess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11NWGjXRmjXk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Savee dataset\n",
    "\n",
    "The audio files in this dataset are named in such a way that the prefix letters describes the emotion classes as follows:\n",
    "\n",
    "* 'a' = 'anger'\n",
    "* 'd' = 'disgust'\n",
    "* 'f' = 'fear'\n",
    "* 'h' = 'happiness'\n",
    "* 'n' = 'neutral'\n",
    "* 'sa' = 'sadness'\n",
    "* 'su' = 'surprise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:18.932235Z",
     "iopub.status.busy": "2023-01-30T21:05:18.931797Z",
     "iopub.status.idle": "2023-01-30T21:05:19.124834Z",
     "shell.execute_reply": "2023-01-30T21:05:19.124027Z",
     "shell.execute_reply.started": "2023-01-30T21:05:18.932186Z"
    },
    "id": "69vtwZfCGagN",
    "outputId": "6871b4bf-4099-4ce2-fe37-d66525db1982",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "savee_directiory_list = os.listdir(Savee)\n",
    "\n",
    "emotion_df = []\n",
    "\n",
    "for wav in savee_directiory_list:\n",
    "    info = wav.partition(\".wav\")[0].split(\"_\")[1].replace(r\"[0-9]\", \"\")\n",
    "    emotion = re.split(r\"[0-9]\", info)[0]\n",
    "    if emotion=='a':\n",
    "        emotion_df.append((\"angry\", Savee + \"/\" + wav))\n",
    "    elif emotion=='d':\n",
    "        emotion_df.append((\"disgust\", Savee + \"/\" + wav))\n",
    "    elif emotion=='f':\n",
    "        emotion_df.append((\"fear\", Savee + \"/\" + wav))\n",
    "    elif emotion=='h':\n",
    "        emotion_df.append((\"happy\", Savee + \"/\" + wav))\n",
    "    elif emotion=='n':\n",
    "        emotion_df.append((\"neutral\", Savee + \"/\" + wav))\n",
    "    elif emotion=='sa':\n",
    "        emotion_df.append((\"sad\", Savee + \"/\" + wav))\n",
    "    else:\n",
    "        emotion_df.append((\"surprise\", Savee + \"/\" + wav))\n",
    "\n",
    "\n",
    "Savee_df = pd.DataFrame.from_dict(emotion_df)\n",
    "Savee_df.rename(columns={1 : \"Path\", 0 : \"Emotion\"}, inplace=True)\n",
    "\n",
    "Savee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:21.259531Z",
     "iopub.status.busy": "2023-01-30T21:05:21.259145Z",
     "iopub.status.idle": "2023-01-30T21:05:21.269685Z",
     "shell.execute_reply": "2023-01-30T21:05:21.268755Z",
     "shell.execute_reply.started": "2023-01-30T21:05:21.259497Z"
    },
    "id": "y7cNw4CiGagO",
    "outputId": "d34ff2ec-48aa-4abe-d7b8-93f950e0e5f2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's concat all datasets together for doing some analysis\n",
    "df = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:34.160559Z",
     "iopub.status.busy": "2023-01-30T21:05:34.160233Z",
     "iopub.status.idle": "2023-01-30T21:05:34.171782Z",
     "shell.execute_reply": "2023-01-30T21:05:34.170701Z",
     "shell.execute_reply.started": "2023-01-30T21:05:34.160530Z"
    },
    "id": "L5sJCqEHGagP",
    "outputId": "176937ce-85f2-4922-d6bb-c227688fdff1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:42.187292Z",
     "iopub.status.busy": "2023-01-30T21:05:42.186959Z",
     "iopub.status.idle": "2023-01-30T21:05:42.192803Z",
     "shell.execute_reply": "2023-01-30T21:05:42.191745Z",
     "shell.execute_reply.started": "2023-01-30T21:05:42.187258Z"
    },
    "id": "uVi0-uAoGagR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:48.842443Z",
     "iopub.status.busy": "2023-01-30T21:05:48.842083Z",
     "iopub.status.idle": "2023-01-30T21:05:49.007128Z",
     "shell.execute_reply": "2023-01-30T21:05:49.006276Z",
     "shell.execute_reply.started": "2023-01-30T21:05:48.842412Z"
    },
    "id": "WVBt0GHIJWy4",
    "outputId": "0a2a17a1-f3b3-47df-f2e3-aeaf4561d1ce"
   },
   "outputs": [],
   "source": [
    "plt.title(\"Count of emotions:\")\n",
    "sns.countplot(x=df[\"Emotion\"])\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:56.621369Z",
     "iopub.status.busy": "2023-01-30T21:05:56.620947Z",
     "iopub.status.idle": "2023-01-30T21:05:56.632704Z",
     "shell.execute_reply": "2023-01-30T21:05:56.631593Z",
     "shell.execute_reply.started": "2023-01-30T21:05:56.621333Z"
    },
    "id": "xqDOP7R4mjXn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_waveplot(data, sr, e):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.title(f'Waveplot for audio with {e} emotion', size=15)\n",
    "    librosa.display.waveplot(data, sr=sr)\n",
    "    plt.show()\n",
    "\n",
    "def create_spectrogram(data, sr, e):\n",
    "    # stft function converts the data into short term fourier transform\n",
    "    X = librosa.stft(data)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title('Spectrogram for audio with {} emotion'.format(e), size=15)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:05:57.539600Z",
     "iopub.status.busy": "2023-01-30T21:05:57.539274Z",
     "iopub.status.idle": "2023-01-30T21:05:58.926844Z",
     "shell.execute_reply": "2023-01-30T21:05:58.925735Z",
     "shell.execute_reply.started": "2023-01-30T21:05:57.539568Z"
    },
    "id": "C6qf_0_omjXo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotion='fear'\n",
    "path = np.array(df.Path[df.Emotion==emotion])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate, emotion)\n",
    "create_spectrogram(data, sampling_rate, emotion)\n",
    "Audio(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:06:15.715472Z",
     "iopub.status.busy": "2023-01-30T21:06:15.715119Z",
     "iopub.status.idle": "2023-01-30T21:06:16.266984Z",
     "shell.execute_reply": "2023-01-30T21:06:16.265834Z",
     "shell.execute_reply.started": "2023-01-30T21:06:15.715440Z"
    },
    "id": "BCzDKBbUmjXo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotion='angry'\n",
    "path = np.array(df.Path[df.Emotion==emotion])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate, emotion)\n",
    "create_spectrogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:06:24.971493Z",
     "iopub.status.busy": "2023-01-30T21:06:24.971131Z",
     "iopub.status.idle": "2023-01-30T21:06:25.518118Z",
     "shell.execute_reply": "2023-01-30T21:06:25.517264Z",
     "shell.execute_reply.started": "2023-01-30T21:06:24.971460Z"
    },
    "id": "27pC1njemjXp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotion='sad'\n",
    "path = np.array(df.Path[df.Emotion==emotion])[1]\n",
    "data, sampling_rate = librosa.load(path)\n",
    "create_waveplot(data, sampling_rate, emotion)\n",
    "create_spectrogram(data, sampling_rate, emotion)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdC6RrASGagU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data augmentation\n",
    "\n",
    "We have some ways for data augmentation in sound data:\n",
    "\n",
    "1. Noise injection\n",
    "2. Stretching\n",
    "3. Shifting\n",
    "4. Pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:01.740553Z",
     "iopub.status.busy": "2023-01-30T21:07:01.740149Z",
     "iopub.status.idle": "2023-01-30T21:07:01.751699Z",
     "shell.execute_reply": "2023-01-30T21:07:01.750646Z",
     "shell.execute_reply.started": "2023-01-30T21:07:01.740516Z"
    },
    "id": "K6VOGR9WGagV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def noise(data, random=False, rate=0.035, threshold=0.075):\n",
    "    \"\"\"Add some noise to sound sample. Use random if you want to add random noise with some threshold.\n",
    "    Or use rate Random=False and rate for always adding fixed noise.\"\"\"\n",
    "    if random:\n",
    "        rate = np.random.random() * threshold\n",
    "    noise_amp = rate*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def stretch(data, rate=0.8):\n",
    "    \"\"\"Stretching data with some rate.\"\"\"\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "\n",
    "def shift(data, rate=1000):\n",
    "    \"\"\"Shifting data with some rate\"\"\"\n",
    "    shift_range = int(np.random.uniform(low=-5, high = 5)*rate)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_factor=0.7, random=False):\n",
    "    \"\"\"\"Add some pitch to sound sample. Use random if you want to add random pitch with some threshold.\n",
    "    Or use pitch_factor Random=False and rate for always adding fixed pitch.\"\"\"\n",
    "    if random:\n",
    "        pitch_factor=np.random.random() * pitch_factor\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:06.173399Z",
     "iopub.status.busy": "2023-01-30T21:07:06.173037Z",
     "iopub.status.idle": "2023-01-30T21:07:06.182731Z",
     "shell.execute_reply": "2023-01-30T21:07:06.181875Z",
     "shell.execute_reply.started": "2023-01-30T21:07:06.173367Z"
    },
    "id": "xitP8RUdJ_Ih",
    "outputId": "941f993f-d438-4c57-c973-9e58b7f0a585"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:09.089304Z",
     "iopub.status.busy": "2023-01-30T21:07:09.088961Z",
     "iopub.status.idle": "2023-01-30T21:07:09.275065Z",
     "shell.execute_reply": "2023-01-30T21:07:09.274263Z",
     "shell.execute_reply.started": "2023-01-30T21:07:09.089265Z"
    },
    "id": "4_9-uM8iGagZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = df[df[\"Emotion\"] == \"happy\"][\"Path\"].iloc[0]\n",
    "data, sampling_rate = librosa.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fK1iIUiGaga",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Simple audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:13.850970Z",
     "iopub.status.busy": "2023-01-30T21:07:13.850639Z",
     "iopub.status.idle": "2023-01-30T21:07:13.989332Z",
     "shell.execute_reply": "2023-01-30T21:07:13.988633Z",
     "shell.execute_reply.started": "2023-01-30T21:07:13.850939Z"
    },
    "id": "SKHhjYyAGaga",
    "outputId": "9db4f6d0-a2e4-4682-b078-35f71bc19078",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(data, sampling_rate)\n",
    "Audio(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bualD5imGagb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Noised audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:16.791218Z",
     "iopub.status.busy": "2023-01-30T21:07:16.790875Z",
     "iopub.status.idle": "2023-01-30T21:07:16.932226Z",
     "shell.execute_reply": "2023-01-30T21:07:16.931135Z",
     "shell.execute_reply.started": "2023-01-30T21:07:16.791179Z"
    },
    "id": "QuYLG0MNGagb",
    "outputId": "187c74fb-a69b-413b-e5e5-b05c74b474d1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noised_data = noise(data, random=True)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=noised_data, sr=sampling_rate)\n",
    "Audio(noised_data, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h8PSBmKGagc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Stretching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:18.975493Z",
     "iopub.status.busy": "2023-01-30T21:07:18.975125Z",
     "iopub.status.idle": "2023-01-30T21:07:19.626025Z",
     "shell.execute_reply": "2023-01-30T21:07:19.625040Z",
     "shell.execute_reply.started": "2023-01-30T21:07:18.975462Z"
    },
    "id": "KtcZfmTuGagc",
    "outputId": "978bc23d-b93c-4d83-c885-d8ea66428708",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stretched_data = stretch(data, rate=0.5)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=stretched_data, sr=sampling_rate)\n",
    "Audio(stretched_data, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7-Q0o00Gagd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Shifting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:21.359382Z",
     "iopub.status.busy": "2023-01-30T21:07:21.359000Z",
     "iopub.status.idle": "2023-01-30T21:07:21.523111Z",
     "shell.execute_reply": "2023-01-30T21:07:21.522265Z",
     "shell.execute_reply.started": "2023-01-30T21:07:21.359346Z"
    },
    "id": "9nEk49f2Gagd",
    "outputId": "48adbd70-c7fb-4bfb-a803-babe8087892a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shifted_data = shift(data)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=shifted_data, sr=sampling_rate)\n",
    "Audio(shifted_data, rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81SrhOGbGage",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Pitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:07:58.191472Z",
     "iopub.status.busy": "2023-01-30T21:07:58.191104Z",
     "iopub.status.idle": "2023-01-30T21:07:58.418498Z",
     "shell.execute_reply": "2023-01-30T21:07:58.417609Z",
     "shell.execute_reply.started": "2023-01-30T21:07:58.191441Z"
    },
    "id": "ISd3ua1lGage",
    "outputId": "80b55d11-ba7a-4ef9-c55a-be2295c42b61",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pitched_data = pitch(data, sampling_rate, pitch_factor=0.5, random=True)\n",
    "plt.figure(figsize=(14,4))\n",
    "librosa.display.waveplot(y=pitched_data, sr=sampling_rate)\n",
    "Audio(pitched_data, rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9daF5SXGagf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For our data augmentation we will use noise and pitch and combination with both of it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQIofybCGagf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature extraction\n",
    "\n",
    "#### There are some features may be useful:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbXSGC0xGagg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Zero Crossing Rate : The rate of sign-changes of the signal during the duration of a particular frame.\n",
    "2. Energy : The sum of squares of the signal values, normalized by the respective frame length.\n",
    "3. Entropy of Energy :The entropy of sub-frames’ normalized energies. It can be interpreted as a measure of abrupt changes.\n",
    "3. Spectral Centroid : The center of gravity of the spectrum.\n",
    "4. Spectral Spread : The second central moment of the spectrum.\n",
    "5. Spectral Entropy : Entropy of the normalized spectral energies for a set of sub-frames.\n",
    "6. Spectral Flux : The squared difference between the normalized magnitudes of the spectra of the two successive frames.\n",
    "7. Spectral Rolloff : The frequency below which 90% of the magnitude distribution of the spectrum is concentrated.\n",
    "8. MFCCs Mel Frequency Cepstral Coefficients form a cepstral representation where the frequency bands are not linear but distributed according to the mel-scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:08:50.149966Z",
     "iopub.status.busy": "2023-01-30T21:08:50.149617Z",
     "iopub.status.idle": "2023-01-30T21:08:50.155044Z",
     "shell.execute_reply": "2023-01-30T21:08:50.154064Z",
     "shell.execute_reply.started": "2023-01-30T21:08:50.149935Z"
    },
    "id": "V-IbBcNOGagi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "hop_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:08:57.101253Z",
     "iopub.status.busy": "2023-01-30T21:08:57.100907Z",
     "iopub.status.idle": "2023-01-30T21:08:57.392565Z",
     "shell.execute_reply": "2023-01-30T21:08:57.391528Z",
     "shell.execute_reply.started": "2023-01-30T21:08:57.101220Z"
    },
    "id": "HWjRoq9fGagi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chunks(data, frame_length, hop_length):\n",
    "    for i in range(0, len(data), hop_length):\n",
    "        yield data[i:i+frame_length]\n",
    "\n",
    "# Zero Crossing Rate\n",
    "def zcr(data, frame_length=2048, hop_length=512):\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(zcr)\n",
    "\n",
    "\n",
    "def energy(data, frame_length=2048, hop_length=512):\n",
    "    en = np.array([np.sum(np.power(np.abs(data[hop:hop+frame_length]), 2)) for hop in range(0, data.shape[0], hop_length)])\n",
    "    return en / frame_length\n",
    "\n",
    "\n",
    "def rmse(data, frame_length=2048, hop_length=512):\n",
    "    rmse = librosa.feature.rms(y=data, frame_length=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(rmse)\n",
    "\n",
    "\n",
    "def entropy_of_energy(data, frame_length=2048, hop_length=512):\n",
    "    energies = energy(data, frame_length, hop_length)\n",
    "    energies /= np.sum(energies)\n",
    "\n",
    "    entropy = 0.0\n",
    "    entropy -= energies * np.log2(energies)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def spc(data, sr, frame_length=2048, hop_length=512):\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(spectral_centroid)\n",
    "\n",
    "\n",
    "def spc_flux(data):\n",
    "    isSpectrum = data.ndim == 1\n",
    "    if isSpectrum:\n",
    "        data = np.expand_dims(data, axis=1)\n",
    "\n",
    "    X = np.c_[data[:, 0], data]\n",
    "    af_Delta_X = np.diff(X, 1, axis=1)\n",
    "    vsf = np.sqrt((np.power(af_Delta_X, 2).sum(axis=0))) / X.shape[0]\n",
    "\n",
    "    return np.squeeze(vsf) if isSpectrum else vsf\n",
    "\n",
    "\n",
    "def spc_rollof(data, sr, frame_length=2048, hop_length=512):\n",
    "    spcrollof = librosa.feature.spectral_rolloff(y=data, sr=sr, n_fft=frame_length, hop_length=hop_length)\n",
    "    return np.squeeze(spcrollof)\n",
    "\n",
    "\n",
    "def chroma_stft(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
    "    return np.squeeze(chroma_stft.T) if not flatten else np.ravel(chroma_stft.T)\n",
    "\n",
    "\n",
    "def mel_spc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mel = librosa.feature.melspectrogram(y=data, sr=sr)\n",
    "    return np.squeeze(mel.T) if not flatten else np.ravel(mel.T)\n",
    "\n",
    "def mfcc(data, sr, frame_length=2048, hop_length=512, flatten: bool = True):\n",
    "    mfcc_feature = librosa.feature.mfcc(y=data, sr=sr)\n",
    "    return np.squeeze(mfcc_feature.T) if not flatten else np.ravel(mfcc_feature.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOe6p69xGagk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Let's check data formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:08:57.394629Z",
     "iopub.status.busy": "2023-01-30T21:08:57.394126Z",
     "iopub.status.idle": "2023-01-30T21:08:57.563350Z",
     "shell.execute_reply": "2023-01-30T21:08:57.562534Z",
     "shell.execute_reply.started": "2023-01-30T21:08:57.394580Z"
    },
    "id": "hg_lxHJGGagl",
    "outputId": "fcabeeec-4582-4ae4-8362-c4854c697996",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = np.array(df[\"Path\"])[658]\n",
    "data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:09:01.028902Z",
     "iopub.status.busy": "2023-01-30T21:09:01.028581Z",
     "iopub.status.idle": "2023-01-30T21:09:01.090917Z",
     "shell.execute_reply": "2023-01-30T21:09:01.090233Z",
     "shell.execute_reply.started": "2023-01-30T21:09:01.028873Z"
    },
    "id": "3matXCLMGagm",
    "outputId": "8e5eadb9-0878-4697-8703-870677306038",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"ZCR: \", zcr(data).shape)\n",
    "print(\"Energy: \", energy(data).shape)\n",
    "print(\"Entropy of Energy :\", entropy_of_energy(data).shape)\n",
    "print(\"RMS :\", rmse(data).shape)\n",
    "print(\"Spectral Centroid :\", spc(data, sampling_rate).shape)\n",
    "# print(\"Spectral Entropy: \", spc_entropy(data, sampling_rate).shape)\n",
    "print(\"Spectral Flux: \", spc_flux(data).shape)\n",
    "print(\"Spectral Rollof: \", spc_rollof(data, sampling_rate).shape)\n",
    "print(\"Chroma STFT: \", chroma_stft(data, sampling_rate).shape)\n",
    "print(\"MelSpectrogram: \", mel_spc(data, sampling_rate).shape)\n",
    "print(\"MFCC: \", mfcc(data, sampling_rate).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KE8lP2iOmjX1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In experimental way was decided to use just 3 main features for this task: *ZCR*, *RMS* and *MFCC*.\n",
    "\n",
    "Also in experimental way  was decided to use just 2.5s duration with 0.6 offset - in the dataset first 0.6s contains\n",
    "no information about emotion, and most of them are less then 3s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:09:06.482955Z",
     "iopub.status.busy": "2023-01-30T21:09:06.482639Z",
     "iopub.status.idle": "2023-01-30T21:09:06.489744Z",
     "shell.execute_reply": "2023-01-30T21:09:06.487506Z",
     "shell.execute_reply.started": "2023-01-30T21:09:06.482926Z"
    },
    "id": "ptqBhohMGagn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(data, sr, frame_length=2048, hop_length=512):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result,\n",
    "                        zcr(data, frame_length, hop_length),\n",
    "                        # np.mean(energy(data, frame_length, hop_length),axis=0),\n",
    "                        # np.mean(entropy_of_energy(data, frame_length, hop_length), axis=0),\n",
    "                        rmse(data, frame_length, hop_length),\n",
    "                        # spc(data, sr, frame_length, hop_length),\n",
    "                        # spc_entropy(data, sr),\n",
    "                        # spc_flux(data),\n",
    "                        # spc_rollof(data, sr, frame_length, hop_length),\n",
    "                        # chroma_stft(data, sr, frame_length, hop_length),\n",
    "                        # mel_spc(data, sr, frame_length, hop_length, flatten=True)\n",
    "                        mfcc(data, sr, frame_length, hop_length)\n",
    "                                    ))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:09:08.532090Z",
     "iopub.status.busy": "2023-01-30T21:09:08.531770Z",
     "iopub.status.idle": "2023-01-30T21:09:08.539327Z",
     "shell.execute_reply": "2023-01-30T21:09:08.538482Z",
     "shell.execute_reply.started": "2023-01-30T21:09:08.532059Z"
    },
    "id": "syOHatlkGagn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(path, duration=2.5, offset=0.6):\n",
    "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
    "    data, sample_rate = librosa.load(path, duration=duration, offset=offset)\n",
    "\n",
    "     # without augmentation\n",
    "    res1 = extract_features(data, sample_rate)\n",
    "    result = np.array(res1)\n",
    "\n",
    "    # data with noise\n",
    "    noise_data = noise(data, random=True)\n",
    "    res2 = extract_features(noise_data, sample_rate)\n",
    "    result = np.vstack((result, res2)) # stacking vertically\n",
    "\n",
    "    # data with pitching\n",
    "    pitched_data = pitch(data, sample_rate, random=True)\n",
    "    res3 = extract_features(pitched_data, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    # data with pitching and white_noise\n",
    "    new_data = pitch(data, sample_rate, random=True)\n",
    "    data_noise_pitch = noise(new_data, random=True)\n",
    "    res3 = extract_features(data_noise_pitch, sample_rate)\n",
    "    result = np.vstack((result, res3)) # stacking vertically\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T21:09:12.729890Z",
     "iopub.status.busy": "2023-01-30T21:09:12.729573Z",
     "iopub.status.idle": "2023-01-30T21:49:55.955122Z",
     "shell.execute_reply": "2023-01-30T21:49:55.954068Z",
     "shell.execute_reply.started": "2023-01-30T21:09:12.729859Z"
    },
    "id": "VKSrqq87Gago",
    "outputId": "c1f5ca81-f2b3-4e27-efc4-4298c76fe068",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "print(\"Feature processing...\")\n",
    "for path, emotion, ind in zip(df.Path, df.Emotion, range(df.Path.shape[0])):\n",
    "    features = get_features(path)\n",
    "    if ind % 100 == 0:\n",
    "        print(f\"{ind} samples has been processed...\")\n",
    "    for ele in features:\n",
    "        X.append(ele)\n",
    "        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n",
    "        Y.append(emotion)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7vX-imImjX4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's save our features as DataFrame for further processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:00:52.258179Z",
     "iopub.status.busy": "2023-01-30T22:00:52.257855Z",
     "iopub.status.idle": "2023-01-30T22:00:52.263624Z",
     "shell.execute_reply": "2023-01-30T22:00:52.262019Z",
     "shell.execute_reply.started": "2023-01-30T22:00:52.258136Z"
    },
    "id": "m1FVI7o-oHAA"
   },
   "outputs": [],
   "source": [
    "features_path = \"./features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:00:06.259383Z",
     "iopub.status.busy": "2023-01-30T22:00:06.258956Z",
     "iopub.status.idle": "2023-01-30T22:00:45.931436Z",
     "shell.execute_reply": "2023-01-30T22:00:45.930181Z",
     "shell.execute_reply.started": "2023-01-30T22:00:06.259345Z"
    },
    "id": "-gz_e0r0Gagp",
    "outputId": "807c807d-42f0-45f7-ac32-f353a575cc18",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extracted_df = pd.DataFrame(X)\n",
    "extracted_df[\"labels\"] = Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:01:02.065464Z",
     "iopub.status.busy": "2023-01-30T22:01:02.065125Z",
     "iopub.status.idle": "2023-01-30T22:03:36.705109Z",
     "shell.execute_reply": "2023-01-30T22:03:36.704260Z",
     "shell.execute_reply.started": "2023-01-30T22:01:02.065435Z"
    }
   },
   "outputs": [],
   "source": [
    "extracted_df.to_csv(features_path, index=False)\n",
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:05:15.797640Z",
     "iopub.status.busy": "2023-01-30T22:05:15.797307Z",
     "iopub.status.idle": "2023-01-30T22:05:39.880946Z",
     "shell.execute_reply": "2023-01-30T22:05:39.879965Z",
     "shell.execute_reply.started": "2023-01-30T22:05:15.797608Z"
    },
    "id": "ttq3hBHMGagq",
    "outputId": "766808e5-5f13-416c-ff0a-5f67e26152fa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# extracted_df = pd.read_csv(features_path)\n",
    "# print(extracted_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:08:14.510793Z",
     "iopub.status.busy": "2023-01-30T22:08:14.510467Z",
     "iopub.status.idle": "2023-01-30T22:08:20.091271Z",
     "shell.execute_reply": "2023-01-30T22:08:20.090272Z",
     "shell.execute_reply.started": "2023-01-30T22:08:14.510763Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:30:00.055597Z",
     "iopub.status.busy": "2023-01-30T22:30:00.055260Z",
     "iopub.status.idle": "2023-01-30T22:30:01.763882Z",
     "shell.execute_reply": "2023-01-30T22:30:01.762914Z",
     "shell.execute_reply.started": "2023-01-30T22:30:00.055568Z"
    },
    "id": "iAfiqFkX9W3V",
    "outputId": "3b424535-1bfd-4097-837d-bd151065db4a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fill NaN with 0\n",
    "extracted_df = extracted_df.fillna(0)\n",
    "print(extracted_df.isna().any())\n",
    "extracted_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:30:04.325109Z",
     "iopub.status.busy": "2023-01-30T22:30:04.324798Z",
     "iopub.status.idle": "2023-01-30T22:30:04.350154Z",
     "shell.execute_reply": "2023-01-30T22:30:04.349337Z",
     "shell.execute_reply.started": "2023-01-30T22:30:04.325081Z"
    },
    "id": "amvMhwYy9W3W",
    "outputId": "181bdcd3-68a0-475c-cb42-5996817d7f98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extracted_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHv-RWWyGagr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "As of now we have extracted the data, now we need to normalize and split our data for training and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:30:08.834290Z",
     "iopub.status.busy": "2023-01-30T22:30:08.833962Z",
     "iopub.status.idle": "2023-01-30T22:30:09.127559Z",
     "shell.execute_reply": "2023-01-30T22:30:09.126637Z",
     "shell.execute_reply.started": "2023-01-30T22:30:08.834259Z"
    },
    "id": "C7EJLI7uGagr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = extracted_df.drop(labels=\"labels\", axis=1)\n",
    "Y = extracted_df[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:30:12.164523Z",
     "iopub.status.busy": "2023-01-30T22:30:12.164208Z",
     "iopub.status.idle": "2023-01-30T22:30:12.182934Z",
     "shell.execute_reply": "2023-01-30T22:30:12.182063Z",
     "shell.execute_reply.started": "2023-01-30T22:30:12.164493Z"
    },
    "id": "kFz36z24Gags",
    "outputId": "6ac476f1-4350-436b-c673-45f3546d3784",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "Y = np_utils.to_categorical(lb.fit_transform(Y))\n",
    "print(lb.classes_)\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:31:22.276406Z",
     "iopub.status.busy": "2023-01-30T22:31:22.276050Z",
     "iopub.status.idle": "2023-01-30T22:31:23.678060Z",
     "shell.execute_reply": "2023-01-30T22:31:23.677137Z",
     "shell.execute_reply.started": "2023-01-30T22:31:22.276377Z"
    },
    "id": "PQIfMHUzGags",
    "outputId": "40bafb84-e3eb-4fb8-8e6a-a9ccc7819194",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.2, shuffle=True)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:31:42.011193Z",
     "iopub.status.busy": "2023-01-30T22:31:42.010844Z",
     "iopub.status.idle": "2023-01-30T22:31:43.074059Z",
     "shell.execute_reply": "2023-01-30T22:31:43.073230Z",
     "shell.execute_reply.started": "2023-01-30T22:31:42.011138Z"
    },
    "id": "bdXUA9ThGagt",
    "outputId": "ef935895-bde6-4cbf-d472-6cdf4f175862",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42, test_size=0.1, shuffle=True)\n",
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:32:03.218851Z",
     "iopub.status.busy": "2023-01-30T22:32:03.218540Z",
     "iopub.status.idle": "2023-01-30T22:32:03.224494Z",
     "shell.execute_reply": "2023-01-30T22:32:03.223270Z",
     "shell.execute_reply.started": "2023-01-30T22:32:03.218821Z"
    }
   },
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:33:27.099633Z",
     "iopub.status.busy": "2023-01-30T22:33:27.099302Z",
     "iopub.status.idle": "2023-01-30T22:33:27.104115Z",
     "shell.execute_reply": "2023-01-30T22:33:27.103222Z",
     "shell.execute_reply.started": "2023-01-30T22:33:27.099602Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:24.482049Z",
     "iopub.status.busy": "2023-01-30T22:34:24.481736Z",
     "iopub.status.idle": "2023-01-30T22:34:26.408815Z",
     "shell.execute_reply": "2023-01-30T22:34:26.407857Z",
     "shell.execute_reply.started": "2023-01-30T22:34:24.482017Z"
    },
    "id": "6TLov1F5Gagt",
    "outputId": "a3b1a2ba-146b-41d0-8658-e25b251561b0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:31.722811Z",
     "iopub.status.busy": "2023-01-30T22:34:31.722484Z",
     "iopub.status.idle": "2023-01-30T22:34:31.729378Z",
     "shell.execute_reply": "2023-01-30T22:34:31.728521Z",
     "shell.execute_reply.started": "2023-01-30T22:34:31.722781Z"
    },
    "id": "0V_49McG9W3Y",
    "outputId": "0f676dc5-f4ec-46ce-e05b-0034f8ba8680",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We have to use 1-dimensional CNN which need specifical shape:\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_val = np.expand_dims(X_val, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tjWv5gQouVn"
   },
   "source": [
    "### Let's define our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:35.584908Z",
     "iopub.status.busy": "2023-01-30T22:34:35.584595Z",
     "iopub.status.idle": "2023-01-30T22:34:35.589005Z",
     "shell.execute_reply": "2023-01-30T22:34:35.587919Z",
     "shell.execute_reply.started": "2023-01-30T22:34:35.584878Z"
    },
    "id": "jHEEtvs3Gagu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor =\"val_acc\",\n",
    "                              mode = 'auto', patience = 5,\n",
    "                              restore_best_weights = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:40.059168Z",
     "iopub.status.busy": "2023-01-30T22:34:40.058836Z",
     "iopub.status.idle": "2023-01-30T22:34:40.063519Z",
     "shell.execute_reply": "2023-01-30T22:34:40.062761Z",
     "shell.execute_reply.started": "2023-01-30T22:34:40.059128Z"
    },
    "id": "2blnhORSGagv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:42.708666Z",
     "iopub.status.busy": "2023-01-30T22:34:42.708326Z",
     "iopub.status.idle": "2023-01-30T22:34:42.717732Z",
     "shell.execute_reply": "2023-01-30T22:34:42.716565Z",
     "shell.execute_reply.started": "2023-01-30T22:34:42.708635Z"
    },
    "id": "Sr4GRdD5Gagv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:47.609053Z",
     "iopub.status.busy": "2023-01-30T22:34:47.608730Z",
     "iopub.status.idle": "2023-01-30T22:34:50.115691Z",
     "shell.execute_reply": "2023-01-30T22:34:50.114710Z",
     "shell.execute_reply.started": "2023-01-30T22:34:47.609022Z"
    },
    "id": "cnJ23ul8Gagv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv1D(512, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\",\n",
    "                        input_shape=(X_train.shape[1], 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(layers.Conv1D(512, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(layers.Conv1D(256, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPool1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(layers.Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(layers.Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling1D(pool_size=3, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(7, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"acc\", f1_m])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:34:50.117513Z",
     "iopub.status.busy": "2023-01-30T22:34:50.117153Z",
     "iopub.status.idle": "2023-01-30T22:34:50.132474Z",
     "shell.execute_reply": "2023-01-30T22:34:50.131583Z",
     "shell.execute_reply.started": "2023-01-30T22:34:50.117479Z"
    },
    "id": "8GGgAbmGGagw",
    "outputId": "e0da41eb-3ee9-4bca-9c98-eedec081e4e0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:35:14.334070Z",
     "iopub.status.busy": "2023-01-30T22:35:14.333754Z",
     "iopub.status.idle": "2023-01-30T22:35:14.338234Z",
     "shell.execute_reply": "2023-01-30T22:35:14.337107Z",
     "shell.execute_reply.started": "2023-01-30T22:35:14.334040Z"
    },
    "id": "OodmLqTYGagw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T22:35:18.531441Z",
     "iopub.status.busy": "2023-01-30T22:35:18.530950Z",
     "iopub.status.idle": "2023-01-30T23:16:57.609239Z",
     "shell.execute_reply": "2023-01-30T23:16:57.608476Z",
     "shell.execute_reply.started": "2023-01-30T22:35:18.531402Z"
    },
    "id": "kR_nW-IaGagx",
    "outputId": "d5d8553d-f0d8-4dbb-90a7-ca0d6d7bdf99",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=EPOCHS, batch_size=batch_size,\n",
    "                    callbacks=[earlystopping, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:09.199450Z",
     "iopub.status.busy": "2023-01-30T23:17:09.198972Z",
     "iopub.status.idle": "2023-01-30T23:17:17.053242Z",
     "shell.execute_reply": "2023-01-30T23:17:17.052266Z",
     "shell.execute_reply.started": "2023-01-30T23:17:09.199403Z"
    },
    "id": "YsAZPEBUGagx",
    "outputId": "833a6cd0-9716-45b3-fdb4-83b2238c9aab",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy of our model on test data : \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")\n",
    "\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['acc']\n",
    "train_loss = history.history['loss']\n",
    "test_acc = history.history['val_acc']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(train_loss, label = 'Training Loss')\n",
    "ax[0].plot(test_loss , label = 'Testing Loss')\n",
    "ax[0].set_title('Training & Testing Loss')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(train_acc, label = 'Training Accuracy')\n",
    "ax[1].plot(test_acc , label = 'Testing Accuracy')\n",
    "ax[1].set_title('Training & Testing Accuracy')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:24.413319Z",
     "iopub.status.busy": "2023-01-30T23:17:24.412882Z",
     "iopub.status.idle": "2023-01-30T23:17:31.032618Z",
     "shell.execute_reply": "2023-01-30T23:17:31.031870Z",
     "shell.execute_reply.started": "2023-01-30T23:17:24.413283Z"
    },
    "id": "wdVIn0e-L59M",
    "outputId": "79c8fb74-112b-4599-9639-3b35047217b4"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:36.677188Z",
     "iopub.status.busy": "2023-01-30T23:17:36.676850Z",
     "iopub.status.idle": "2023-01-30T23:17:36.683581Z",
     "shell.execute_reply": "2023-01-30T23:17:36.682771Z",
     "shell.execute_reply.started": "2023-01-30T23:17:36.677138Z"
    },
    "id": "6FkgEXhLMMIq",
    "outputId": "9e45b7ec-1b96-47d9-bf77-9de704fa3aff"
   },
   "outputs": [],
   "source": [
    "y_check = np.argmax(y_test, axis=1)\n",
    "y_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:40.836043Z",
     "iopub.status.busy": "2023-01-30T23:17:40.835723Z",
     "iopub.status.idle": "2023-01-30T23:17:40.850603Z",
     "shell.execute_reply": "2023-01-30T23:17:40.849913Z",
     "shell.execute_reply.started": "2023-01-30T23:17:40.836014Z"
    },
    "id": "y6g7Tfixvl-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_check, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:49.190910Z",
     "iopub.status.busy": "2023-01-30T23:17:49.190588Z",
     "iopub.status.idle": "2023-01-30T23:17:49.200639Z",
     "shell.execute_reply": "2023-01-30T23:17:49.199771Z",
     "shell.execute_reply.started": "2023-01-30T23:17:49.190878Z"
    },
    "id": "ny5RzRQsv-HB"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:53.068296Z",
     "iopub.status.busy": "2023-01-30T23:17:53.067866Z",
     "iopub.status.idle": "2023-01-30T23:17:53.426002Z",
     "shell.execute_reply": "2023-01-30T23:17:53.425150Z",
     "shell.execute_reply.started": "2023-01-30T23:17:53.068243Z"
    },
    "id": "uaXgVyMawGCP",
    "outputId": "80486dec-0722-44b6-90d5-f4eed60bf404"
   },
   "outputs": [],
   "source": [
    "cm_plot_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:18:01.640043Z",
     "iopub.status.busy": "2023-01-30T23:18:01.639715Z",
     "iopub.status.idle": "2023-01-30T23:18:01.785009Z",
     "shell.execute_reply": "2023-01-30T23:18:01.784135Z",
     "shell.execute_reply.started": "2023-01-30T23:18:01.640012Z"
    },
    "id": "lt4_1Oc_Gagy"
   },
   "outputs": [],
   "source": [
    "path_to_model = \"./res_model.h5\"\n",
    "\n",
    "model.save(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:21:24.227563Z",
     "iopub.status.busy": "2023-01-30T23:21:24.227231Z",
     "iopub.status.idle": "2023-01-30T23:21:24.300056Z",
     "shell.execute_reply": "2023-01-30T23:21:24.299199Z",
     "shell.execute_reply.started": "2023-01-30T23:21:24.227533Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
